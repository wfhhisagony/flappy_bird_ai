{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# you can use this file to train the model in some cloud platform"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f78f18af0479cddd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c398fe7896c4610"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from pygame import image as pyg_image\n",
    "from pygame import mixer as pyg_mixer\n",
    "from pygame import Rect\n",
    "from pygame.transform import flip as img_flip\n",
    "from pygame.transform import smoothscale\n",
    "\n",
    "\n",
    "_BASE_DIR = r\"E:\\MyCode\\pythonCode\\flappy_bird_ai\"  # remember to change this\n",
    "\n",
    "SPRITES_PATH = os.path.join(_BASE_DIR, \"assets/images\")\n",
    "AUDIO_PATH = os.path.join(_BASE_DIR , \"assets/sounds\")\n",
    "\n",
    "PLAYER_WIDTH = 30\n",
    "PLAYER_HEIGHT = 25\n",
    "\n",
    "BACKGROUND_WIDTH = 360\n",
    "BACKGROUND_HEIGHT = 450\n",
    "\n",
    "PIPE_WIDTH = PLAYER_WIDTH\n",
    "PIPE_HEIGHT = int(BACKGROUND_HEIGHT * 0.7)\n",
    "\n",
    "class Utils:\n",
    "    def __int__(self):\n",
    "        pass\n",
    "    @staticmethod\n",
    "    def pixel_collision(rect1: Rect,\n",
    "                        rect2: Rect,\n",
    "                        hitmask1: List[List[bool]],\n",
    "                        hitmask2: List[List[bool]]) -> bool:\n",
    "        \"\"\" Checks if two objects collide and not just their rects. \"\"\"\n",
    "        rect = rect1.clip(rect2)\n",
    "    \n",
    "        if rect.width == 0 or rect.height == 0:\n",
    "            return False\n",
    "    \n",
    "        x1, y1 = rect.x - rect1.x, rect.y - rect1.y\n",
    "        x2, y2 = rect.x - rect2.x, rect.y - rect2.y\n",
    "    \n",
    "        for x in range(rect.width):\n",
    "            for y in range(rect.height):\n",
    "                if hitmask1[x1+x][y1+y] and hitmask2[x2+x][y2+y]:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_hitmask(image) -> List[List[bool]]:\n",
    "        \"\"\" Returns a hitmask using an image's alpha. \"\"\"\n",
    "        mask = []\n",
    "        for x in range(image.get_width()):\n",
    "            mask.append([])\n",
    "            for y in range(image.get_height()):\n",
    "                mask[x].append(bool(image.get_at((x, y))[3]))\n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_sprite(filename, convert, alpha=True):\n",
    "        img = pyg_image.load(f\"{SPRITES_PATH}/{filename}\")\n",
    "        return (img.convert_alpha() if convert and alpha\n",
    "                else img.convert() if convert\n",
    "                else img)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_images(convert: bool = True,\n",
    "                    bg_type: Optional[str] = None) -> Dict[str, Any]:  # 根据game_logic调整的图片大小(写死的)\n",
    "        \"\"\" Loads and returns the image assets of the game. \"\"\"\n",
    "        images = {}\n",
    "    \n",
    "        try:\n",
    "            if bg_type is None:\n",
    "                images[\"background\"] = None\n",
    "            else:\n",
    "                images[\"background\"] = smoothscale(Utils._load_sprite(f\"{bg_type}.png\",\n",
    "                                                    convert=convert, alpha=False), (BACKGROUND_WIDTH, BACKGROUND_HEIGHT))\n",
    "        \n",
    "            # Bird sprites:\n",
    "            images[\"player\"] = (\n",
    "                smoothscale(Utils._load_sprite(f\"bird_up.png\",\n",
    "                             convert=convert, alpha=True),(PLAYER_WIDTH, PLAYER_HEIGHT)),\n",
    "                smoothscale(Utils._load_sprite(f\"bird_middle.png\",\n",
    "                             convert=convert, alpha=True),(PLAYER_WIDTH, PLAYER_HEIGHT)),\n",
    "                smoothscale(Utils._load_sprite(f\"bird_down.png\",\n",
    "                             convert=convert, alpha=True),(PLAYER_WIDTH, PLAYER_HEIGHT)),\n",
    "            )\n",
    "        \n",
    "            # Pipe sprites:\n",
    "            pipe_sprite = smoothscale(Utils._load_sprite(f\"pipe.png\",\n",
    "                                       convert=convert, alpha=True),(PIPE_WIDTH, PIPE_HEIGHT))\n",
    "            images[\"pipe\"] = (img_flip(pipe_sprite, False, True),\n",
    "                              pipe_sprite)  # up_pipe and low_pipe\n",
    "        except FileNotFoundError as ex:\n",
    "            raise FileNotFoundError(\"Can't find the sprites folder! No such file or\"\n",
    "                                    f\" directory: {SPRITES_PATH}\") from ex\n",
    "        return images\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_sounds() -> Dict[str, pyg_mixer.Sound]:\n",
    "        \"\"\" Loads and returns the audio assets of the game. \"\"\"\n",
    "        pyg_mixer.init()\n",
    "        sounds = {}\n",
    "        try:\n",
    "            sounds[\"game_over\"] = pyg_mixer.Sound(os.path.join(AUDIO_PATH, \"game_over.wav\"))\n",
    "            sounds[\"hit\"] = pyg_mixer.Sound(os.path.join(AUDIO_PATH, \"hit.wav\"))\n",
    "            sounds[\"score\"] = pyg_mixer.Sound(os.path.join(AUDIO_PATH, \"score.mp3\"))\n",
    "            sounds[\"jump\"] = pyg_mixer.Sound(os.path.join(AUDIO_PATH, \"jump.wav\"))\n",
    "            sounds[\"btn_click\"] = pyg_mixer.Sound(os.path.join(AUDIO_PATH, \"btn_click.wav\"))\n",
    "            sounds[\"main_theme\"] = pyg_mixer.Sound(os.path.join(AUDIO_PATH, \"main_theme.mp3\"))\n",
    "            sounds[\"world_clear\"] = pyg_mixer.Sound(os.path.join(AUDIO_PATH, \"world_clear.wav\"))\n",
    "        except FileNotFoundError as ex:\n",
    "            raise FileNotFoundError(\"Can't find the audio folder! No such file or \"\n",
    "                                    f\"directory: {AUDIO_PATH}\") from ex\n",
    "    \n",
    "        return sounds\n",
    "utils = Utils()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:02.474971800Z",
     "start_time": "2024-02-25T14:12:02.441484600Z"
    }
   },
   "id": "6cea8a33b52070b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## game_logic"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa6299b3db0f53ad"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import random\n",
    "from enum import IntEnum\n",
    "from itertools import cycle\n",
    "from typing import Dict, Tuple, Union\n",
    "\n",
    "import pygame\n",
    "\n",
    "############################ Speed and Acceleration ############################\n",
    "PIPE_VEL_X = -4\n",
    "\n",
    "PLAYER_MAX_VEL_Y = 10  # max vel along Y, max descend speed\n",
    "PLAYER_MIN_VEL_Y = -8  # min vel along Y, max ascend speed\n",
    "\n",
    "PLAYER_ACC_Y = 1  # players downward acceleration\n",
    "PLAYER_VEL_ROT = 5  # angular speed\n",
    "\n",
    "PLAYER_FLAP_ACC = -9  # players speed on flapping\n",
    "################################################################################\n",
    "\n",
    "\n",
    "################################## Dimensions ##################################\n",
    "PLAYER_WIDTH = 30\n",
    "PLAYER_HEIGHT = 25\n",
    "\n",
    "BACKGROUND_WIDTH = 360\n",
    "BACKGROUND_HEIGHT = 450\n",
    "\n",
    "PIPE_WIDTH = PLAYER_WIDTH\n",
    "PIPE_HEIGHT = int(BACKGROUND_HEIGHT * 0.7)\n",
    "PIPE_DISTANCE = 120  # 管道之间距离\n",
    "NUM_PIPE_ON_SCREEN = BACKGROUND_WIDTH // 120\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class FlappyBirdLogic:\n",
    "    def __init__(self,\n",
    "                 screen_size: Tuple[int, int],\n",
    "                 pipe_gap_size: int = 100) -> None:\n",
    "        self._screen_width = screen_size[0]\n",
    "        self._screen_height = screen_size[1]\n",
    "\n",
    "        self.player_x = int(self._screen_width * 0.2)\n",
    "        self.player_y = int((self._screen_height - PLAYER_HEIGHT) / 2)\n",
    "\n",
    "        self.score = 0\n",
    "        self._pipe_gap_size = pipe_gap_size\n",
    "\n",
    "        # Generate 2 new pipes to add to upper_pipes and lower_pipes lists\n",
    "        # new_pipe1 = self._get_random_pipe()\n",
    "        # new_pipe2 = self._get_random_pipe()\n",
    "        tmp_pipe_list = [self._get_random_pipe() for i in range(NUM_PIPE_ON_SCREEN+1)]\n",
    "\n",
    "        # List of upper pipes:\n",
    "        self.upper_pipes = [\n",
    "            {\"x\": self._screen_width + i * PIPE_DISTANCE, \"y\": tmp_pipe_list[i][0][\"y\"]}\n",
    "            for i in range(NUM_PIPE_ON_SCREEN+1)\n",
    "        ]\n",
    "        # self.upper_pipes = [\n",
    "        #     {\"x\": self._screen_width + PIPE_DISTANCE,\n",
    "        #      \"y\": new_pipe1[0][\"y\"]},\n",
    "        #     {\"x\": self._screen_width + PIPE_DISTANCE + PIPE_DISTANCE,\n",
    "        #      \"y\": new_pipe2[0][\"y\"]},\n",
    "        # ]\n",
    "\n",
    "        # List of lower pipes:\n",
    "        self.lower_pipes = [\n",
    "            {\"x\": self._screen_width + i * PIPE_DISTANCE, \"y\": tmp_pipe_list[i][1][\"y\"]}\n",
    "            for i in range(NUM_PIPE_ON_SCREEN+1)\n",
    "        ]\n",
    "\n",
    "        # self.lower_pipes = [\n",
    "        #     {\"x\": self._screen_width + PIPE_DISTANCE,\n",
    "        #      \"y\": new_pipe1[1][\"y\"]},\n",
    "        #     {\"x\": self._screen_width + PIPE_DISTANCE + PIPE_DISTANCE,\n",
    "        #      \"y\": new_pipe2[1][\"y\"]},\n",
    "        # ]\n",
    "\n",
    "        # Player's info:\n",
    "        self.player_vel_y = -9  # player's velocity along Y\n",
    "        self.player_rot = 45  # player's rotation\n",
    "\n",
    "        self.last_action = None\n",
    "        self.sound_cache = None\n",
    "\n",
    "        self._player_flapped = False\n",
    "        self.player_idx = 0\n",
    "        self._player_idx_gen = cycle([0, 1, 2, 1])\n",
    "        self._loop_iter = 0\n",
    "\n",
    "    class Actions(IntEnum):  # 注意是一个类来定义枚举量(或共同体Union)\n",
    "        \"\"\" Possible actions for the player to take. \"\"\"\n",
    "        IDLE, FLAP = 0, 1\n",
    "\n",
    "    def _get_random_pipe(self) -> Dict[str, int]:\n",
    "        \"\"\" Returns a randomly generated pipe. \"\"\"\n",
    "        # y of gap between upper and lower pipe\n",
    "        gap_y = random.randrange(0,\n",
    "                                 int(self._screen_height * 0.6 - self._pipe_gap_size))\n",
    "        gap_y += int(self._screen_height * 0.2)\n",
    "\n",
    "        pipe_x = self._screen_width + PIPE_DISTANCE  # 我这里恰好屏幕容纳整数个pipe,则第一个pipe要消失时，即它的x在最左边时，就要添加一个新的x在最右边\n",
    "        return [\n",
    "            {\"x\": pipe_x, \"y\": gap_y - PIPE_HEIGHT},  # upper pipe\n",
    "            {\"x\": pipe_x, \"y\": gap_y + self._pipe_gap_size},  # lower pipe\n",
    "        ]\n",
    "\n",
    "    def check_crash(self) -> bool:\n",
    "        \"\"\" Returns True if player collides with the ground (base) or a pipe.\n",
    "        \"\"\"\n",
    "        if self.player_y + PLAYER_HEIGHT >= self._screen_height or self.player_y < -1:  # 撞地板或天花板\n",
    "            return True\n",
    "        else:\n",
    "            player_rect = pygame.Rect(self.player_x, self.player_y,\n",
    "                                      PLAYER_WIDTH, PLAYER_HEIGHT)\n",
    "\n",
    "            for up_pipe, low_pipe in zip(self.upper_pipes, self.lower_pipes):\n",
    "                # upper and lower pipe rects\n",
    "                up_pipe_rect = pygame.Rect(up_pipe['x'], up_pipe['y'],\n",
    "                                           PIPE_WIDTH, PIPE_HEIGHT)\n",
    "                low_pipe_rect = pygame.Rect(low_pipe['x'], low_pipe['y'],\n",
    "                                            PIPE_WIDTH, PIPE_HEIGHT)\n",
    "\n",
    "                # check collision  Use pygame.Rect.colliderect to do this\n",
    "                up_collide = player_rect.colliderect(up_pipe_rect)\n",
    "                low_collide = player_rect.colliderect(low_pipe_rect)\n",
    "\n",
    "                if up_collide or low_collide:\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def update_state(self, action: Union[Actions, int]) -> bool:\n",
    "        \"\"\" Given an action taken by the player, updates the game's state.\n",
    "\n",
    "        Args:\n",
    "            action (Union[FlappyBirdLogic.Actions, int]): The action taken by\n",
    "                the player.\n",
    "\n",
    "        Returns:\n",
    "            `True` if the player is alive and `False` otherwise.\n",
    "        更新了的（重要的):\n",
    "          self.sound_cache = str  # 该播放的音乐名称\n",
    "          self.player_y\n",
    "          self.pipes\n",
    "        \"\"\"\n",
    "        self.sound_cache = None  # 该播放的音乐名称\n",
    "        if action == FlappyBirdLogic.Actions.FLAP:\n",
    "            if self.player_y > -2 * PLAYER_HEIGHT:\n",
    "                self.player_vel_y = PLAYER_FLAP_ACC  # 迅速改变为上升的速度\n",
    "                self._player_flapped = True\n",
    "                self.sound_cache = \"jump\"\n",
    "\n",
    "        self.last_action = action  # 跟新action\n",
    "        if self.check_crash():\n",
    "            self.sound_cache = \"hit\"\n",
    "            return False  # die\n",
    "\n",
    "        # check for score  检测鸟中间坐标是否过了管子中间坐标\n",
    "        player_mid_pos = self.player_x + PLAYER_WIDTH / 2\n",
    "        for pipe in self.upper_pipes:\n",
    "            pipe_mid_pos = pipe['x'] + PIPE_WIDTH / 2\n",
    "            if pipe_mid_pos <= player_mid_pos < pipe_mid_pos + (-PIPE_VEL_X):  # 使用一个区间来保证每对管子只会加一次分\n",
    "                self.score += 1\n",
    "                self.sound_cache = \"score\"\n",
    "\n",
    "        # player_index change  显示鸟拍翅膀的动画\n",
    "        if (self._loop_iter + 1) % 3 == 0:\n",
    "            self.player_idx = next(self._player_idx_gen)\n",
    "\n",
    "        self._loop_iter = (self._loop_iter + 1) % 30\n",
    "\n",
    "        # rotate the player\n",
    "        if self.player_rot > -70:\n",
    "            self.player_rot -= PLAYER_VEL_ROT\n",
    "\n",
    "        # player's movement\n",
    "        if self.player_vel_y < PLAYER_MAX_VEL_Y and not self._player_flapped:\n",
    "            self.player_vel_y += PLAYER_ACC_Y  # 自动下落\n",
    "\n",
    "        if self._player_flapped:\n",
    "            self._player_flapped = False\n",
    "\n",
    "            # more rotation to cover the threshold\n",
    "            # (calculated in visible rotation)\n",
    "            self.player_rot = 45\n",
    "\n",
    "        self.player_y += min(self.player_vel_y,\n",
    "                             self._screen_height - self.player_y - PLAYER_HEIGHT)  # 不能掉到地板以下\n",
    "\n",
    "        # move pipes to left\n",
    "        for up_pipe, low_pipe in zip(self.upper_pipes, self.lower_pipes):\n",
    "            up_pipe['x'] += PIPE_VEL_X\n",
    "            low_pipe['x'] += PIPE_VEL_X\n",
    "\n",
    "        # add new pipe when first pipe is about to touch left of screen\n",
    "        # if len(self.upper_pipes) > 0 and 0 < self.upper_pipes[0]['x'] <= (-PIPE_VEL_X):\n",
    "\n",
    "\n",
    "        # remove first pipe if its out of the screen\n",
    "        if (len(self.upper_pipes) > 0 and\n",
    "                self.upper_pipes[0]['x'] < -PIPE_WIDTH):\n",
    "            self.upper_pipes.pop(0)\n",
    "            self.lower_pipes.pop(0)\n",
    "            new_pipes = self._get_random_pipe()\n",
    "            self.upper_pipes.append(new_pipes[0])\n",
    "            self.lower_pipes.append(new_pipes[1])\n",
    "\n",
    "        return True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:02.521871600Z",
     "start_time": "2024-02-25T14:12:02.459428100Z"
    }
   },
   "id": "800f29fdc628b530"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## renderer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24333f82c7795b1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#: Player's rotation threshold.\n",
    "PLAYER_ROT_THR = 20\n",
    "\n",
    "#: Color to fill the surface's background when no background image was loaded.\n",
    "FILL_BACKGROUND_COLOR = (200, 200, 200)\n",
    "pygame.font.init()\n",
    "FONT_NAME = \"fangsong\"\n",
    "FONT = pygame.font.SysFont(FONT_NAME, 20)\n",
    "FONT.bold = True\n",
    "\n",
    "class FlappyBirdRenderer:\n",
    "    \"\"\" Handles the rendering of the game.\n",
    "\n",
    "    This class implements the game's renderer, responsible from drawing the game\n",
    "    on the screen.\n",
    "\n",
    "    Args:\n",
    "        screen_size (Tuple[int, int]): The screen's width and height.\n",
    "        audio_on (bool): Whether the game's audio is ON or OFF.\n",
    "        background (str): Type of background image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 screen_size: Tuple[int, int] = (288, 512),\n",
    "                 audio_on: bool = True,\n",
    "                 background: Optional[str] = \"day\") -> None:\n",
    "        self._screen_width = screen_size[0]\n",
    "        self._screen_height = screen_size[1]\n",
    "\n",
    "        self.display = None\n",
    "        self.surface = pygame.Surface(screen_size)\n",
    "        self.images = utils.load_images(convert=False,\n",
    "                                        bg_type=background)\n",
    "        self.audio_on = audio_on\n",
    "        self._audio_queue = []\n",
    "        if audio_on:\n",
    "            self.sounds = utils.load_sounds()\n",
    "\n",
    "        self.game = None  # game_logic\n",
    "        self._clock = pygame.time.Clock()  # FPS\n",
    "\n",
    "    def make_display(self) -> None:\n",
    "        \"\"\" Initializes the pygame's display.\n",
    "\n",
    "        Required for drawing images on the screen.\n",
    "        \"\"\"\n",
    "        self.display = pygame.display.set_mode((self._screen_width,\n",
    "                                                self._screen_height))\n",
    "        # self.images全部的键值对的值全部变成tuple即(, , ,)的形式\n",
    "        for name, value in self.images.items():\n",
    "            if value is None:\n",
    "                continue\n",
    "\n",
    "            if type(value) in (tuple, list):\n",
    "                self.images[name] = tuple([img.convert_alpha()\n",
    "                                           for img in value])\n",
    "            else:\n",
    "                self.images[name] = (value.convert() if name == \"background\"\n",
    "                                     else value.convert_alpha())\n",
    "\n",
    "    def _draw_score(self) -> None:\n",
    "        \"\"\" Draws the score in the center of the surface. \"\"\"\n",
    "\n",
    "        self.surface.blit(FONT.render(f\"{self.game.score}\", True, (0, 0, 0)), (self._screen_width // 2, 10))\n",
    "\n",
    "    def draw_surface(self, show_score: bool = True) -> None:\n",
    "        \"\"\" Re-draws the renderer's surface.\n",
    "\n",
    "        This method updates the renderer's surface by re-drawing it according to\n",
    "        the current state of the game.\n",
    "\n",
    "        Args:\n",
    "            show_score (bool): Whether to draw the player's score or not.\n",
    "        \"\"\"\n",
    "        if self.game is None:\n",
    "            raise ValueError(\"A game logic must be assigned to the renderer!\")\n",
    "\n",
    "        # Background\n",
    "        if self.images['background'] is not None:\n",
    "            self.surface.blit(self.images['background'], (0, 0))\n",
    "        else:\n",
    "            self.surface.fill(FILL_BACKGROUND_COLOR)\n",
    "\n",
    "        # Pipes\n",
    "        for up_pipe, low_pipe in zip(self.game.upper_pipes,\n",
    "                                     self.game.lower_pipes):\n",
    "            self.surface.blit(self.images['pipe'][0],\n",
    "                              (up_pipe['x'], up_pipe['y']))\n",
    "            self.surface.blit(self.images['pipe'][1],\n",
    "                              (low_pipe['x'], low_pipe['y']))\n",
    "\n",
    "        # Score\n",
    "        # (must be drawn before the player, so the player overlaps it)\n",
    "        if show_score:\n",
    "            self._draw_score()\n",
    "\n",
    "        # Getting player's rotation\n",
    "        visible_rot = PLAYER_ROT_THR\n",
    "        if self.game.player_rot <= PLAYER_ROT_THR:\n",
    "            visible_rot = self.game.player_rot\n",
    "\n",
    "        # Player\n",
    "        player_surface = pygame.transform.rotate(\n",
    "            self.images['player'][self.game.player_idx],\n",
    "            visible_rot,\n",
    "        )\n",
    "\n",
    "        self.surface.blit(player_surface, (self.game.player_x,\n",
    "                                           self.game.player_y))\n",
    "\n",
    "    def update_display(self) -> None:\n",
    "        \"\"\" Updates the display with the current surface of the renderer.\n",
    "\n",
    "        A call to this method is usually preceded by a call to\n",
    "        :meth:`.draw_surface()`. This method simply updates the display by\n",
    "        showing the current state of the renderer's surface on it, it doesn't\n",
    "        make any change to the surface.\n",
    "        \"\"\"\n",
    "        if self.display is None:\n",
    "            raise RuntimeError(\n",
    "                \"Tried to update the display, but a display hasn't been \"\n",
    "                \"created yet! To create a display for the renderer, you must \"\n",
    "                \"call the `make_display()` method.\"\n",
    "            )\n",
    "\n",
    "        self.display.blit(self.surface, [0, 0])\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Sounds:\n",
    "        if self.audio_on and self.game.sound_cache is not None:\n",
    "            sound_name = self.game.sound_cache\n",
    "            self.sounds[sound_name].play()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:02.556072500Z",
     "start_time": "2024-02-25T14:12:02.528926200Z"
    }
   },
   "id": "d424d2b94cfbfa8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## flappy_bird_env"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "439fc14d354e997a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Optional, Union\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "class FlappyBirdEnv(gym.Env):  # custom env using gym\n",
    "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"]}  # 其实在这里human mode 和 rgb_array没什么区别,就是render函数返回不同而已,不过压根不会用render函数的返回值\n",
    "\n",
    "    def __init__(self,\n",
    "                 screen_size: Tuple[int, int] = (360, 450),\n",
    "                 pipe_gap: int = 100,\n",
    "                 background: Optional[str] = None\n",
    "                 ):\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = gym.spaces.Box(0, 255, [*screen_size, 3])\n",
    "        self._screen_size = screen_size\n",
    "        self._pipe_gap = pipe_gap\n",
    "\n",
    "        self._game = None  # game_logic的实例\n",
    "        self._renderer = FlappyBirdRenderer(screen_size=self._screen_size,\n",
    "                                            background=background)\n",
    "\n",
    "    def _get_observation(self):\n",
    "        self._renderer.draw_surface(show_score=False)\n",
    "        return pygame.surfarray.array3d(self._renderer.surface)  # 返回的是图片矩阵\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" Resets the environment (starts a new game).\n",
    "        return a current game screen shot and don't include a info_dict\n",
    "        \"\"\"\n",
    "        self._game = FlappyBirdLogic(screen_size=self._screen_size,\n",
    "                                     pipe_gap_size=self._pipe_gap)\n",
    "\n",
    "        self._renderer.game = self._game\n",
    "        return self._get_observation()\n",
    "\n",
    "\n",
    "\n",
    "    def step(self,\n",
    "             action: Union[FlappyBirdLogic.Actions, int],\n",
    "         )-> Tuple[np.ndarray, float, bool, Dict]:\n",
    "        \"\"\"\n",
    "        :param\n",
    "            action(Union[FlappyBirdLogic.Actions, int]): The action taken by\n",
    "                the agent. Zero (0) means \"do nothing\" and one (1) means \"flap\".\n",
    "        :return:\n",
    "         A tuple containing, respectively:\n",
    "\n",
    "                * an observation (RGB-array representing the game's screen);\n",
    "                * a reward (always 1);\n",
    "                * a status report (`True` if the game is over and `False`\n",
    "                  otherwise);\n",
    "                * an info dictionary.\n",
    "        \"\"\"\n",
    "        alive = self._game.update_state(action)\n",
    "        obs = self._get_observation()\n",
    "\n",
    "        reward = 0.1   # redefined reward，你可能需要重新定义reward在你自己的游戏中\n",
    "        done = not alive\n",
    "        if done:\n",
    "            reward = -2.8\n",
    "        elif self._game.sound_cache == 'score':\n",
    "            reward = 2.8\n",
    "\n",
    "        info = {\"score\": self._game.score}\n",
    "\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def render(self, mode=\"human\") -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        If ``mode`` is:\n",
    "\n",
    "            - human: render to the current display. Usually for human\n",
    "              consumption.\n",
    "            - rgb_array: Return an numpy.ndarray with shape (x, y, 3),\n",
    "              representing RGB values for an x-by-y pixel image, suitable\n",
    "              for turning into a video.\n",
    "        :return:\n",
    "            `None` if ``mode`` is \"human\" and a numpy.ndarray with RGB values if\n",
    "            it's \"rgb_array\"\n",
    "        \"\"\"\n",
    "        if mode not in FlappyBirdEnv.metadata[\"render.modes\"]:\n",
    "            raise ValueError(\"Invalid render mode!\")\n",
    "\n",
    "        self._renderer.draw_surface(show_score=True)\n",
    "        if mode == \"rgb_array\":\n",
    "            return pygame.surfarray.array3d(self._renderer.surface)  # infact not need this return, use step()'s return is enough\n",
    "        else:\n",
    "            if self._renderer.display is None:\n",
    "                self._renderer.make_display()\n",
    "\n",
    "            self._renderer.update_display()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\" Closes the environment. \"\"\"\n",
    "        if self._renderer is not None:\n",
    "            pygame.display.quit()\n",
    "            self._renderer = None\n",
    "        super().close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:02.693976500Z",
     "start_time": "2024-02-25T14:12:02.563579700Z"
    }
   },
   "id": "111a2ccf6a49a394"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DQN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a00e8a86d75f585"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    \"\"\"\n",
    "        input: shape(batch_size, 4,84,84)\n",
    "    \"\"\"\n",
    "    def __init__(self, frame_num=4, n_actions=2):\n",
    "        super(DQN, self).__init__()\n",
    "        # 参数\n",
    "        self.number_of_actions = n_actions\n",
    "\n",
    "        self.conv1 = nn.Conv2d(frame_num, 32, 8, 4)  # (84-8)/4+1 = 20\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 2)  # (20-4)/2+1=9\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1)  # (9-3)/1+1 = 7\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(3136, 512)  # 7x7x64 = 3136\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc5 = nn.Linear(512, self.number_of_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.fc5(out)\n",
    "\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:04.427363400Z",
     "start_time": "2024-02-25T14:12:02.692943800Z"
    }
   },
   "id": "b2f71453db99551c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## model_train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cdba6e26ba48708"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class MyToolFunc:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    @staticmethod\n",
    "    def resize_and_bgr2bin(image):\n",
    "        image = cv2.resize(image, (84, 84))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        thresh, image = cv2.threshold(image, 199, 1, cv2.THRESH_BINARY_INV)\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def image_to_tensor(image):\n",
    "        image_tensor = image.transpose(2, 0, 1)\n",
    "        image_tensor = image_tensor.astype(np.float32)\n",
    "        image_tensor = torch.from_numpy(image_tensor)\n",
    "        if torch.cuda.is_available():  # put on GPU if CUDA is available\n",
    "            image_tensor = image_tensor.cuda()\n",
    "        return image_tensor\n",
    "    @staticmethod\n",
    "    def process_state(state):  # make it  a batch input\n",
    "        \"\"\"state is rgb img\"\"\"\n",
    "        state = MyToolFunc.resize_and_bgr2bin(state)\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        return state\n",
    "my_tool_func = MyToolFunc()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:04.441207200Z",
     "start_time": "2024-02-25T14:12:04.428363700Z"
    }
   },
   "id": "6bce0a029737cb73"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<contextlib.ExitStack at 0x1a026beba30>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from itertools import count\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.ion()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:04.796895100Z",
     "start_time": "2024-02-25T14:12:04.441207200Z"
    }
   },
   "id": "a814547c6007bdb3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def init_weights(m):  # 初始化模型权重\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        torch.nn.init.uniform(m.weight, -0.01, 0.01)\n",
    "        m.bias.data.fill_(0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:04.839991100Z",
     "start_time": "2024-02-25T14:12:04.796895100Z"
    }
   },
   "id": "79a2b643aaa9acbc"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "RE_TRAIN_FLAG = False  # False then use the existed model to continue training\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY = 3000\n",
    "TAU = 0.005\n",
    "LR = 1e-4  # learning rate\n",
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = FlappyBirdEnv()\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "n_observations = 4  # each time use four frames\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:05.831602200Z",
     "start_time": "2024-02-25T14:12:04.813353500Z"
    }
   },
   "id": "823dd9bba786f304"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "                    math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            tmp = policy_net(state)\n",
    "            tmp = tmp.max(1).indices.view(1, 1)\n",
    "            return tmp\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                            batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                       if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    # criterion = nn.MSELoss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    # torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:05.848640200Z",
     "start_time": "2024-02-25T14:12:05.844640Z"
    }
   },
   "id": "4f5112512ce4ec38"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use exist model\n"
     ]
    }
   ],
   "source": [
    "save_dir = r\"./my_model\"\n",
    "# 创建路径（如果不存在）\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "if RE_TRAIN_FLAG:\n",
    "    print(\"retrain model\")\n",
    "    init_weights(policy_net)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "else:\n",
    "    print(\"use exist model\")\n",
    "    try:\n",
    "        policy_net.load_state_dict(torch.load(os.path.join(save_dir, 'policy_net.pkl')))\n",
    "        target_net.load_state_dict(torch.load(os.path.join(save_dir, 'target_net.pkl')))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"model files not found: {os.path.join(save_dir, 'policy_net.pkl')} or {os.path.join(save_dir, 'target_net.pkl')}\")\n",
    "        print(\"You can set RE_TRAIN_FLAG=True to retrain the model\")\n",
    "        print(\"automatically retrain model\")\n",
    "        init_weights(policy_net)\n",
    "        target_net.load_state_dict(policy_net.state_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:12:05.874182700Z",
     "start_time": "2024-02-25T14:12:05.851638400Z"
    }
   },
   "id": "cbbced6c350e8a96"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f764a292a54516"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 26000\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "\n",
    "max_score = 1\n",
    "policy_net.train()\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state = env.reset()  # rgb img data:shape(360,450,3)\n",
    "    state = my_tool_func.process_state(state)\n",
    "    state = np.repeat(state, 4, axis=0)  # 最开始将四帧图片全部初始化为第一帧图片\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0) # 作成batch\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        observation, reward, done, info = env.step(action.item())  # observation is rgb img\n",
    "        if info['score'] > max_score:\n",
    "            max_score = info['score']\n",
    "            print(f\"{i_episode}:{info['score']}\")\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        if done:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = my_tool_func.process_state(observation)\n",
    "            next_state = torch.tensor(next_state, dtype=torch.float32, device=device)\n",
    "            next_state = torch.cat((state.squeeze(0)[1:, :, :], next_state)).unsqueeze(0)  # 更新帧组\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key] * TAU + target_net_state_dict[key] * (1 - TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    if (i_episode+1) % 1000 == 0:\n",
    "        print(f\"save,max_score:{max_score}\")\n",
    "        torch.save(target_net.state_dict(), os.path.join(save_dir, f'target_net_{i_episode}.pkl'))\n",
    "        torch.save(policy_net.state_dict(), os.path.join(save_dir, f'policy_net_{i_episode}.pkl'))\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "torch.save(target_net.state_dict(), os.path.join(save_dir, f'target_net_{num_episodes}.pkl'))\n",
    "torch.save(policy_net.state_dict(), os.path.join(save_dir, f'policy_net_{num_episodes}.pkl'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "604545211ca52c7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
